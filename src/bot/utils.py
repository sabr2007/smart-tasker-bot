# src/bot/utils.py
"""Pure utility functions for the Telegram bot.

These functions should NOT import Application, Update, or handlers.
They operate on data and return results.
"""

import json
import logging
import re
from datetime import date
from typing import Optional

import db
from bot.constants import (
    GREETING_WORDS,
    MONTHS_RU,
    STOP_WORDS,
    TASK_VERB_HINTS,
    TIME_HINT_WORDS,
)
from llm_client import render_user_reply
from task_matching import MatchResult, match_task_from_snapshot
from time_utils import now_local, parse_deadline_iso, format_deadline_in_tz, DEFAULT_TIMEZONE

logger = logging.getLogger(__name__)


# ==== SAFE WRAPPERS =====

def safe_render_user_reply(event: dict) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ–±—ë—Ä—Ç—á–∏–∫ –Ω–∞–¥ render_user_reply, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å –∏–∑-–∑–∞ LLM."""
    try:
        return render_user_reply(event)
    except Exception as e:
        logger.exception("render_user_reply failed: %s", e)
        return "–û–ø–µ—Ä–∞—Ü–∏—é —Å–¥–µ–ª–∞–ª, –Ω–æ –Ω–µ —Å–º–æ–≥ –∫—Ä–∞—Å–∏–≤–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç üôÇ"


# ==== TEXT NORMALIZATION =====

def normalize_ru_word(w: str) -> str:
    """
    –ì—Ä—É–±–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤:
    '–∞–Ω–≥–ª–∏–π—Å–∫–∏–π', '–∞–Ω–≥–ª–∏–π—Å–∫–æ–º', '–∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É' ‚Üí '–∞–Ω–≥–ª–∏'
    """
    w = w.lower()
    return re.sub(
        r"(–æ–º—É|–µ–º—É|–æ–≥–æ|–∏–º–∏|—ã–º–∏|–∞–º–∏|–ª—è—Ö|—è—Ö|–∞—Ö|–∞–º|–æ–π|—ã–π|–∏–π|–∞—è|–æ–µ|—ã–µ|—É—é|–æ–º|–µ–≤|–æ–≤|–µ–π|–∞–º–∏?)$",
        "",
        w,
    )


def tokenize_meaningful(text: str) -> list[str]:
    """–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç, –æ—Ç–±—Ä–∞—Å—ã–≤–∞—è —Å—Ç–æ–ø-—Å–ª–æ–≤–∞."""
    tokens = re.findall(r"\w+", text.lower())
    out = []
    for t in tokens:
        if t in STOP_WORDS:
            continue
        norm = normalize_ru_word(t)
        if norm:
            out.append(norm)
    return out


# ==== TEXT DETECTION =====

def is_greeting_only(text: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º –±–µ–∑ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–π —á–∞—Å—Ç–∏.
    –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤—Å–µ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–∑ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π.
    """
    tokens = re.findall(r"\w+", text.lower())
    if not tokens:
        return False

    # –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–∏/–¥–µ–π—Å—Ç–≤–∏–π ‚Äî –Ω–µ —Å—á–∏—Ç–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º
    if any(t in TIME_HINT_WORDS for t in tokens) or any(t in TASK_VERB_HINTS for t in tokens):
        return False

    return all(tok in GREETING_WORDS for tok in tokens)


def is_deadline_like(text: str) -> bool:
    """
    –ì—Ä—É–±–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø–æ—Ö–æ–∂–µ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –æ—Ç–≤–µ—Ç —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º,
    –∞ –Ω–µ –Ω–∞ –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É.
    """
    lower = text.lower()

    # –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∏–ø–∏—á–Ω—ã–π –≥–ª–∞–≥–æ–ª-–∑–∞–¥–∞—á–∞ ‚Üí —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞
    for v in TASK_VERB_HINTS:
        if v in lower:
            return False

    # –µ—Å—Ç—å –ª–∏ –º–∞—Ä–∫–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–∏/–¥–∞—Ç—ã
    has_time_word = any(w in lower for w in TIME_HINT_WORDS)
    has_time_pattern = bool(re.search(r"\d{1,2}:\d{2}", lower))
    has_date_pattern = bool(re.search(r"\d{1,2}\.\d{1,2}(\.\d{2,4})?", lower))

    # —Ö–∞–∫: "–≤ 9 –≤–µ—á–µ—Ä–∞/—É—Ç—Ä–∞/–Ω–æ—á–∏" –±–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏—è
    has_hour_with_part_of_day = bool(
        re.search(r"\b\d{1,2}\b", lower)
        and any(
            w in lower
            for w in [
                "–≤–µ—á–µ—Ä",
                "–≤–µ—á–µ—Ä–∞",
                "–≤–µ—á–µ—Ä–æ–º",
                "—É—Ç—Ä–æ",
                "—É—Ç—Ä–∞",
                "—É—Ç—Ä–æ–º",
                "–Ω–æ—á—å",
                "–Ω–æ—á–∏",
                "–Ω–æ—á—å—é",
            ]
        )
    )

    return has_time_word or has_time_pattern or has_date_pattern or has_hour_with_part_of_day


def detect_rename_intent(text: str) -> dict | None:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å —Å–∏–≥–Ω–∞–ª –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ –∏–∑ —Ñ—Ä–∞–∑—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {"old_hint": str | None, "new_title": str} –∏–ª–∏ None.
    """
    raw = text.strip()
    lower = raw.lower()

    patterns = [
        # "–≤–º–µ—Å—Ç–æ X –∑–∞–¥–∞—á–∞ –Ω–∞–∑—ã–≤–∞–ª–∞—Å—å Y"
        r"–≤–º–µ—Å—Ç–æ\s+\"?(.+?)\"?\s+.*?–Ω–∞–∑\w+\s+\"?(.+?)\"?$",
        # "–ø–µ—Ä–µ–∏–º–µ–Ω—É–π X –≤/–Ω–∞ Y"
        r"–ø–µ—Ä–µ–∏–º–µ–Ω\w*\s+(?:–∑–∞–¥–∞—á—É\s+)?\"?(.+?)\"?\s+(?:–≤|–Ω–∞)\s+\"?(.+?)\"?$",
        # "–∏–∑–º–µ–Ω–∏/–∏—Å–ø—Ä–∞–≤—å X –Ω–∞ Y"
        r"(?:–∏–∑–º–µ–Ω–∏|–∏–∑–º–µ–Ω–∏—Ç—å|–∏—Å–ø—Ä–∞–≤—å)\s+(?:–∑–∞–¥–∞—á—É\s+)?\"?(.+?)\"?\s+–Ω–∞\s+\"?(.+?)\"?$",
        # "–ø–æ–º–µ–Ω—è–π X –Ω–∞ Y" / "–ø–æ–º–µ–Ω—è–µ–º X –Ω–∞ Y"
        r"(?:–∑–∞–¥–∞—á—É\s+)?\"?(.+?)\"?\s+(?:–¥–∞–≤–∞–π\s+)?–ø–æ–º–µ–Ω—è\w*\s+–Ω–∞\s+\"?(.+?)\"?$",
    ]

    for pat in patterns:
        m = re.search(pat, lower, flags=re.IGNORECASE)
        if m and len(m.groups()) >= 2:
            old_hint = m.group(1).strip(" ¬´¬ª\"'""‚Äû")
            new_title = m.group(2).strip(" ¬´¬ª\"'""‚Äû")
            if new_title:
                return {"old_hint": old_hint or None, "new_title": new_title}

    # fallback: "–ø–æ–º–µ–Ω—è–µ–º –Ω–∞ Y" ‚Äî –±–µ–∑ —Å—Ç–∞—Ä–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º target_task_hint –ø–æ–∑–∂–µ
    m = re.search(r"–ø–æ–º–µ–Ω—è\w*\s+(?:.*?\s+)?–Ω–∞\s+\"?(.+?)\"?$", lower, flags=re.IGNORECASE)
    if m:
        new_title = m.group(1).strip(" ¬´¬ª\"'""‚Äû")
        if new_title:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ö–∏–Ω—Ç –∫–∞–∫ –≤—Å—ë –¥–æ —Å–ª–æ–≤–∞ "–ø–æ–º–µ–Ω"
            idx = lower.find("–ø–æ–º–µ–Ω")
            old_part = lower[:idx].strip(" ¬´¬ª\"'""‚Äû")
            old_hint = old_part if old_part else None
            return {"old_hint": old_hint, "new_title": new_title}

    return None


# ==== DATE PARSING =====

def parse_explicit_date(text: str) -> date | None:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –¥–∞—Ç—É –≤–∏–¥–∞ "9 –¥–µ–∫–∞–±—Ä—è" –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç date –∏–ª–∏ None.
    """
    lower = text.lower()
    m = re.search(
        r"\b(\d{1,2})\s+("
        r"—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|"
        r"–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è"
        r")\b",
        lower,
    )
    if not m:
        return None

    day_str, month_word = m.groups()
    day = int(day_str)
    month = MONTHS_RU[month_word]

    now = now_local()
    year = now.year

    try:
        dt = date(year, month, day)
    except ValueError:
        return None

    # –ï—Å–ª–∏ –¥–∞—Ç–∞ —É–∂–µ –ø—Ä–æ—à–ª–∞ –≤ —ç—Ç–æ–º –≥–æ–¥—É ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Ä–µ—á—å –æ —Å–ª–µ–¥—É—é—â–µ–º
    if dt < now.date():
        try:
            dt = date(year + 1, month, day)
        except ValueError:
            return None

    return dt


# ==== FORMATTING =====

def format_deadline_human_local(deadline_iso: Optional[str], user_timezone: str = DEFAULT_TIMEZONE) -> Optional[str]:
    """Format deadline in user's timezone for display.
    
    Args:
        deadline_iso: ISO deadline string (can be UTC or any timezone)
        user_timezone: User's IANA timezone for display
    
    Returns:
        Formatted string like "30.12 15:00" in user's timezone
    """
    if not deadline_iso:
        return None
    # Use new timezone-aware formatting
    result = format_deadline_in_tz(deadline_iso, user_timezone)
    if result:
        return result
    # Fallback to legacy parsing
    try:
        dt = parse_deadline_iso(deadline_iso)
        if not dt:
            return None
        return dt.strftime("%d.%m %H:%M")
    except Exception:
        return None


# ==== TASK MATCHING HELPERS =====

def render_clarification_message(mr: MatchResult) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ-—É—Ç–æ—á–Ω–µ–Ω–∏–µ –∫–æ–≥–¥–∞ –∑–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."""
    base = "–Ø –Ω–µ —É–≤–µ—Ä–µ–Ω, –∫–∞–∫—É—é –∑–∞–¥–∞—á—É —Ç—ã –∏–º–µ–ª –≤ –≤–∏–¥—É. –ù–∞–ø–∏—à–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ —Ü–µ–ª–∏–∫–æ–º, –∫–∞–∫ –æ–Ω–æ –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ."
    if mr.top:
        opts = "\n".join([f"- {c.task_text}" for c in mr.top[:3]])
        return base + "\n\n–í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n" + opts
    return base


def match_task_or_none(
    tasks_snapshot,
    *,
    target_task_hint: str | None,
    raw_input: str,
    action: str,
) -> tuple[tuple[int, str] | None, MatchResult]:
    """–ò—â–µ—Ç –∑–∞–¥–∞—á—É –ø–æ —Ö–∏–Ω—Ç—É –∏ –ª–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    mr = match_task_from_snapshot(tasks_snapshot, target_task_hint, raw_input)
    logger.info(
        "task_match %s",
        json.dumps(
            {
                "action": action,
                "hint": target_task_hint,
                "raw_input": raw_input,
                "reason": mr.reason,
                "threshold": mr.threshold,
                "top": [{"task_id": c.task_id, "score": c.score, "text": c.task_text} for c in mr.top],
                "matched": {
                    "task_id": mr.matched.task_id,
                    "score": mr.matched.score,
                    "text": mr.matched.task_text,
                }
                if mr.matched
                else None,
            },
            ensure_ascii=False,
        ),
    )
    if mr.matched:
        return (mr.matched.task_id, mr.matched.task_text), mr
    return None, mr


async def find_task_by_hint(user_id: int, hint: str):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ –∑–∞–¥–∞—á—É –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –ø–æ–¥—Å–∫–∞–∑–∫–µ.
    –°–Ω–∞—á–∞–ª–∞ —Ç–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ, –ø–æ—Ç–æ–º –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–π fuzzy —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º.
    """
    if not hint:
        return None
    tasks = await db.get_tasks(user_id)
    mr = match_task_from_snapshot(tasks, hint, raw_input=hint)
    if mr.matched:
        return (mr.matched.task_id, mr.matched.task_text)
    return None


async def filter_tasks_by_date(user_id: int, target_date, user_timezone: str = "Asia/Almaty") -> list[tuple[int, str, str | None]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–¥–∞—á–∏, –¥–µ–¥–ª–∞–π–Ω –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∞—Ç–æ–π target_date (–≤ –ª–æ–∫–∞–ª—å–Ω–æ–π TZ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è).
    """
    tasks = await db.get_tasks(user_id)
    result = []
    
    # We need to import utc_to_local inside function or at top level. 
    # Since imports are usually at top, let's assume we update imports too.
    # But for now I'll use simple import here to avoid messing up file just for import
    from time_utils import utc_to_local, parse_deadline_iso
    
    for t_id, text, due in tasks:
        if not due:
            continue
        try:
            # Parse stored deadline (UTC)
            dt = parse_deadline_iso(due)
            if not dt:
                continue
            
            # Convert to user timezone
            local_dt = utc_to_local(dt, user_timezone)
            
            if local_dt.date() == target_date:
                result.append((t_id, text, due))
        except Exception:
            continue
    return result

